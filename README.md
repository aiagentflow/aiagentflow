# aiagentflow

A local-first CLI that orchestrates multi-agent AI workflows for software development. Give it a task â€” or feed it your specs, PRDs, and guidelines â€” and it coordinates specialized agents to architect, code, review, test, and ship automatically.

**No cloud dependency. Bring your own API keys. Your code stays on your machine.**

[![npm version](https://img.shields.io/npm/v/@aiagentflow/cli)](https://www.npmjs.com/package/@aiagentflow/cli)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Node.js](https://img.shields.io/badge/node-%3E%3D20-green)](https://nodejs.org)

---

## How It Works

```
Task â†’ Architect â†’ Coder â†’ Reviewer â†’ Tester â†’ Fixer â†’ Ship
```

Each stage uses a specialized AI agent with tuned prompts and parameters. The loop repeats until quality thresholds pass â€” like a small AI engineering team running on your machine.

---

## Install

```bash
npm install -g @aiagentflow/cli
```

Or with pnpm:

```bash
pnpm add -g @aiagentflow/cli
```

---

## Quick Start

```bash
# 1. Initialize in your project
cd /path/to/your/project
aiagentflow init

# 2. Run a task
aiagentflow run "Add a login form with email/password validation"

# 3. Or run autonomously (no approval prompts)
aiagentflow run "Refactor the auth module" --auto

# 4. Feed context docs to agents
aiagentflow run "Add auth" --context docs/api-spec.md docs/security.md

# 5. Generate a task list from specs, then batch-run
aiagentflow plan docs/prd.md -o tasks.txt
aiagentflow run --batch tasks.txt --auto
```

The `init` wizard walks you through:

1. Select your LLM providers (Anthropic, OpenAI, Ollama)
2. Enter API keys
3. Assign models per agent role
4. Set workflow preferences
5. Import existing docs (specs, requirements, guidelines) for auto-loading

Configuration is saved locally in `.aiagentflow/config.json`.

---

## Features

- **Multi-agent pipeline** â€” 6 specialized agents, each with a distinct role
- **Context-aware** â€” feed specs, PRDs, architecture docs, and guidelines to every agent
- **Plan from docs** â€” generate batch-ready task lists from your existing documentation
- **Local-first** â€” runs entirely on your machine, no code leaves your system
- **Provider-agnostic** â€” Anthropic (Claude), OpenAI (GPT), Ollama (local models), more coming
- **Configurable** â€” tune models, temperature, and iteration limits per agent
- **Git-native** â€” auto-creates branches for each task
- **Human-in-the-loop** â€” approve or override at any stage, or go full auto
- **QA policies** â€” configurable quality gates (max critical issues, test requirements)
- **Batch mode** â€” process multiple tasks from a file
- **Session persistence** â€” crash recovery with automatic session saving
- **Token tracking** â€” monitor LLM usage per agent and per run
- **Customizable prompts** â€” edit agent prompts in `.aiagentflow/prompts/`

---

## CLI Commands

| Command                                       | Description                               |
| --------------------------------------------- | ----------------------------------------- |
| `aiagentflow init`                            | Interactive setup wizard                  |
| `aiagentflow config`                          | View current configuration                |
| `aiagentflow doctor`                          | Health check â€” verify providers and setup |
| `aiagentflow run <task>`                      | Run a workflow for a task                 |
| `aiagentflow run <task> --auto`               | Autonomous mode (no approval prompts)     |
| `aiagentflow run <task> --context <files...>` | Run with reference documents              |
| `aiagentflow run --batch tasks.txt`           | Process multiple tasks from a file        |
| `aiagentflow plan <docs...>`                  | Generate a task list from documentation   |
| `aiagentflow plan <docs...> -o tasks.txt`     | Write task list to file (batch-ready)     |

---

## Agent Roles

| Agent        | Role      | What it does                                         |
| ------------ | --------- | ---------------------------------------------------- |
| ğŸ§  Architect | Plan      | Analyzes the task and creates an implementation plan |
| ğŸ’» Coder     | Implement | Writes production-ready code based on the plan       |
| ğŸ” Reviewer  | Review    | Reviews code for bugs, security, and quality         |
| ğŸ§ª Tester    | Test      | Generates tests and runs them                        |
| ğŸ› Fixer     | Fix       | Addresses review comments and test failures          |
| âœ… Judge     | QA        | Final quality gate â€” pass or fail                    |

---

## Supported Providers

| Provider      | Type      | Setup                                                 |
| ------------- | --------- | ----------------------------------------------------- |
| **Anthropic** | Cloud API | Requires `ANTHROPIC_API_KEY`                          |
| **OpenAI**    | Cloud API | Requires `OPENAI_API_KEY`                             |
| **Ollama**    | Local     | Requires [Ollama](https://ollama.com) running locally |

More providers (Groq, etc.) can be added by implementing a single adapter file.

### Using with Ollama (free, local)

```bash
# Install and start Ollama
ollama serve

# Pull a model
ollama pull llama3.2

# Initialize aiagentflow with Ollama
aiagentflow init
# â†’ Select "ollama" as provider
# â†’ Enter model name: llama3.2
```

### Using with OpenAI (cloud API)

```bash
# Get your API key from https://platform.openai.com/api-keys
export OPENAI_API_KEY=your-api-key

# Initialize aiagentflow with OpenAI
aiagentflow init
# â†’ Select "openai" as provider
# â†’ Enter your API key
# â†’ Choose a model: gpt-4o, gpt-4o-mini, gpt-4-turbo, or gpt-3.5-turbo
```

Available OpenAI models:

- `gpt-4o` - Most capable model, 128K context
- `gpt-4o-mini` - Fast and cost-effective, 128K context
- `gpt-4-turbo` - High performance, 128K context
- `gpt-3.5-turbo` - Fast and affordable, 16K context

---

## Configuration

After `aiagentflow init`, your project has:

```
.aiagentflow/
â”œâ”€â”€ config.json              # Main configuration
â”œâ”€â”€ prompts/                 # Customizable agent prompts
â”‚   â”œâ”€â”€ architect.md
â”‚   â”œâ”€â”€ coder.md
â”‚   â”œâ”€â”€ reviewer.md
â”‚   â”œâ”€â”€ tester.md
â”‚   â”œâ”€â”€ fixer.md
â”‚   â””â”€â”€ judge.md
â”œâ”€â”€ policies/                # Quality standards
â”‚   â””â”€â”€ coding-standards.md
â”œâ”€â”€ context/                 # Reference docs (auto-loaded into every run)
â”‚   â”œâ”€â”€ api-spec.md          # Example: your API specification
â”‚   â””â”€â”€ requirements.md      # Example: your PRD or requirements
â””â”€â”€ sessions/                # Saved workflow sessions
```

Edit the prompt files to customize how each agent behaves. Edit `coding-standards.md` to set project-specific rules that all agents follow. Drop `.md` or `.txt` files into `context/` and they'll be automatically included as reference material for all agents.

---

## Context Documents

Agents work best when they understand your project's requirements, API contracts, and standards. There are three ways to provide reference documents:

**1. Auto-loaded (recommended)** â€” Drop files into `.aiagentflow/context/`:

```bash
cp docs/api-spec.md .aiagentflow/context/
cp docs/security-guidelines.md .aiagentflow/context/
aiagentflow run "Implement user registration"
# Both docs are automatically included in every agent's context
```

**2. Per-run via `--context` flag:**

```bash
aiagentflow run "Add OAuth support" --context docs/oauth-spec.md docs/auth-arch.md
```

**3. During init** â€” The setup wizard asks if you have existing docs and copies them for you.

### What to include

| Document type          | Example             | Why it helps                                      |
| ---------------------- | ------------------- | ------------------------------------------------- |
| API specs              | `api-spec.md`       | Agents generate correct endpoints and contracts   |
| Requirements / PRDs    | `requirements.md`   | Architect plans match your actual requirements    |
| Security guidelines    | `security.md`       | Reviewer catches violations against your policies |
| Architecture docs      | `architecture.md`   | Coder follows your patterns and conventions       |
| Development guidelines | `dev-guidelines.md` | All agents follow your team's standards           |

### Plan command

Turn documentation into an actionable task list, then batch-run it:

```bash
# Generate tasks from a PRD
aiagentflow plan docs/prd.md -o tasks.txt

# Review the generated tasks
cat tasks.txt

# Run them all
aiagentflow run --batch tasks.txt --auto --context docs/architecture.md
```

---

## Project Structure

```
src/
â”œâ”€â”€ cli/            # CLI entry point and commands
â”œâ”€â”€ core/           # Config system, workflow engine, QA policies
â”œâ”€â”€ providers/      # LLM provider adapters (Anthropic, Ollama)
â”œâ”€â”€ agents/         # Agent implementations and prompt library
â”œâ”€â”€ git/            # Git operations wrapper
â”œâ”€â”€ prompts/        # Default prompt templates
â””â”€â”€ utils/          # Shared utilities (logger, fs, validation)
```

---

## Development

```bash
# Clone and install
git clone https://github.com/aiagentflow/aiagentflow.git
cd aiagentflow
pnpm install

# Run in dev mode
pnpm dev run "your task here"

# Type check
pnpm typecheck

# Run tests
pnpm test

# Lint & format
pnpm lint
pnpm format
```

---

## Contributing

Contributions are welcome! Here's how to get started:

1. **Fork** the repo and clone your fork
2. **Create a branch** for your feature: `git checkout -b feature/your-feature`
3. **Follow the coding standards:**
   - Functions: `camelCase`, Classes: `PascalCase`, Files: `kebab-case`
   - All public functions need JSDoc, types, and error handling
   - Use custom `AppError` subclasses â€” never raw `throw new Error()`
4. **Check your work:** `pnpm typecheck && pnpm lint && pnpm test`
5. **Open a PR** against `main` with a description of what and why

### Architecture rules

- Dependency direction flows downward: `cli â†’ core â†’ utils â†’ types`
- Config types are inferred from Zod schemas, never manually defined
- New providers only require one adapter file + registry entry

---

## Roadmap

- [x] Project scaffolding, config system, LLM provider layer
- [x] Workflow engine, agent implementations, Git integration
- [x] QA policies, token tracking, session persistence
- [x] Context documents â€” feed specs, PRDs, and guidelines to agents
- [x] Plan command â€” generate task lists from documentation
- [x] OpenAI provider support
- [ ] More providers (Groq, Mistral)
- [ ] VSCode extension
- [ ] Desktop GUI

---

## License

[MIT](LICENSE)

---

<p align="center">
  <a href="https://aiagentflow.dev">aiagentflow.dev</a>
</p>
